---
title: "Test NBH of HistoCAT with cosine similarity"
output: html_notebook
---

Run histoCAT with all NBH defs and store results after count and after significance testing

```{r}
library(cytomapper)
library(imcRtools)
library(SingleCellExperiment)
library(readr)
library(SpatialExperiment)
library(tidyverse)


# load in data
getwd()

files = list.files("./../../../../data/", pattern = ".csv")
data_path = "./../../../../data/"
data_list = list()

for (i in files){
  print(i)
  data_list[[i]] <- readr::read_csv(paste0(data_path,i))
}
```


```{r}
#add image id name
data_list = Map(cbind, data_list, img_id = names(data_list))
# add other metadata information and join all datasets

data = do.call("rbind", data_list)

# create dataframe with random values to pretend to have expression data to generate a giotto object
df = cbind(rep(1,base::nrow(data)),rep(1,base::nrow(data)))
#df <- as.matrix(runif(nrow(data) * 2), nrow = nrow(data))
colnames(df) = c("M1", "M2")

metadata = as.data.frame(cbind(as.character(data$ct), as.character(data$img_id), rownames(data)))
colnames(metadata) = c("ct", "img_id","cell_ID")

spe = SpatialExperiment(assay=as.data.frame(t(df)), 
                        colData=metadata, 
                        spatialCoords = as.matrix(data[, !(names(data) %in% c("ct", "img_id"))])
)
```


```{r}
spe <- buildSpatialGraph(spe, img_id = "img_id",
                         type = "expansion",
                         threshold = 300,
                         coords = c("x", "y"))
spe <- buildSpatialGraph(spe, img_id = "img_id",
                         type = "knn",
                         k = 20,
                         coords = c("x", "y")) 
spe <- buildSpatialGraph(spe, img_id = "img_id",
                         type = "delaunay",
                         coords = c("x", "y"))

assayNames(spe) = "expr"
```

Delaunay
```{r}

spe <- aggregateNeighbors(spe,
                          colPairName = "delaunay_interaction_graph",
                          aggregate_by = "metadata",
                          count_by = "ct") 



out_del <- countInteractions(spe,
                             group_by = "img_id",
                             label = "ct",
                             method = "histocat",
                             #patch_size = 2,
                             colPairName = "delaunay_interaction_graph")

out_del_sig <- testInteractions(spe,
                        group_by = "img_id",
                        label = "ct",
                        method = "histocat",
                        colPairName = "delaunay_interaction_graph")

```

KNN
```{r}
spe <- aggregateNeighbors(spe,
                          colPairName = "knn_interaction_graph",
                          aggregate_by = "metadata",
                          assay_type = "expr",
                          count_by = "ct"
)

out_knn <- countInteractions(spe,
                         group_by = "img_id",
                         label = "ct",
                         method = "histocat",
                         #patch_size = 2,
                         colPairName = "knn_interaction_graph")
out_knn_sig <- testInteractions(spe,
                        group_by = "img_id",
                        label = "ct",
                        method = "histocat",
                        colPairName = "knn_interaction_graph")


```

Distance
```{r}
spe <- aggregateNeighbors(spe,
                          colPairName = "expansion_interaction_graph",
                          aggregate_by = "metadata",
                          assay_type = "expr",
                          count_by = "ct"
)

out_dis <- countInteractions(spe,
                         group_by = "img_id",
                         label = "ct",
                         method = "histocat",
                         #patch_size = 2,
                         colPairName = "expansion_interaction_graph")
out_dis_sig <- testInteractions(spe,
                        group_by = "img_id",
                        label = "ct",
                        method = "histocat",
                        colPairName = "expansion_interaction_graph")

out_dis_sig_100 = out_dis_sig

```

Comparison

```{r}
# create ground truth matrix with proximity values taken for simulation, these are not necessarily true for the image!
# Take value for heuristic assignment rather, TODO
vec_self = c(0.60, 0.13, 0.13, 0.14, 0.13, 0.29, 0.29, 0.29, 0.13, 0.29, 0.29, 0.29, 0.14, 0.29, 0.29, 0.28)
vec_ran = c(0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25)

# create matrix as ground truth

m = matrix(vec_self, nrow=20, ncol=length(vec_self), byrow=TRUE)
m2 = matrix(vec_ran, nrow=20, ncol=length(vec_ran), byrow=TRUE)

m_true = rbind(m2, m)


```

What are the datasets I have? Put them in a list to have comparison
```{r}
data_sig = list(out_del_sig, out_knn_sig, out_dis_sig)
data_c = list(out_del, out_knn, out_dis)

```

Generate heatmaps to visualize seperation
```{r}
library(ggplot2)
library(pheatmap)
names(data_sig) = c("delaunay", "knn", "distance_100")

for (i in 1:length(data_sig)){
 try = as.data.frame(data_sig[[i]]) %>% select(from_label, to_label, p_lt, group_by)
 try$key = paste(try$from_label, try$to_label, sep = "_")
 try = try %>% select(-c(from_label, to_label))

 try = spread(try, key = key, value = p_lt)

 rownames(try) = try$group_by
 pheatmap(try[,-1], treeheight_row = 0, treeheight_col = 0, main = paste0(names(data_sig)[i], "_significance"))
 
 mat = as.matrix(try[,-1])
 cos_sim <- sum(mat * m_true) / (sqrt(sum(mat^2)) * sqrt(sum(m_true^2)))
 print(cos_sim)
}

```
The same with the count outout and not significance testing

```{r}
for (i in 1:length(data_sig)){
 try = as.data.frame(data_sig[[i]]) %>% select(from_label, to_label, ct, group_by)
 try$key = paste(try$from_label, try$to_label, sep = "_")
 try = try %>% select(-c(from_label, to_label))

 try = spread(try, key = key, value = ct)

 rownames(try) = try$group_by
 pheatmap(try[,-1], treeheight_row = 0, treeheight_col = 0, main = paste0(names(data_sig)[i], "_counts"))
 mat = as.matrix(try[,-1])
 cos_sim <- sum(mat * m_true) / (sqrt(sum(mat^2)) * sqrt(sum(m_true^2)))
 print(cos_sim)
}
```

Q: What do the distances mean in that image? What is a 1?

Create cosine similarity
```{r}
data_sig = list(out_del_sig, out_knn_sig, out_dis_sig)
data_c = list(out_del, out_knn, out_dis)
list = c(data_c, data_sig)

for (i in data_sig){
 try = as.data.frame(data_sig[[i]]) %>% select(from_label, to_label, ct, group_by)
 try$key = paste(try$from_label, try$to_label, sep = "_")
 try = try %>% select(-c(from_label, to_label))
 try = spread(try, key = key, value = ct)

 rownames(try) = try$group_by
  cos_sim <- sum(mat * m_true) / (sqrt(sum(mat^2)) * sqrt(sum(m_true^2)))
  print(cos_sim)
}

for (i in data_sig){
 try = as.data.frame(data_sig[[i]]) %>% select(from_label, to_label, ct, group_by)
 try$key = paste(try$from_label, try$to_label, sep = "_")
 try = try %>% select(-c(from_label, to_label))
 try = spread(try, key = key, value = ct)

 rownames(try) = try$group_by
  cos_sim <- sum(mat * m_true) / (sqrt(sum(mat^2)) * sqrt(sum(m_true^2)))
  print(cos_sim)
}

mat = as.matrix(try[,-1])

```


Use a random forest classifier and give labels to the samples
```{r}
#create matrix for that
try = as.data.frame(data_sig[[1]]) %>% select(from_label, to_label, p_lt, group_by)
 try$key = paste(try$from_label, try$to_label, sep = "_")
 try = try %>% select(-c(from_label, to_label))

 try = spread(try, key = key, value = p_lt)
# Load required libraries
library(randomForest)

# Create the significance matrix with columns as 16 interactions and rows as 40 samples
# Here, I assume the matrix is named 'sig_matrix'
# The first 20 samples are in cohort 0 and the next 20 samples are in cohort 1
# The cohort labels are stored in a vector named 'labels'
sig_matrix <- as.matrix(try[,-1])
labels <- rep(c("A","B"), each=20)


# Train a random forest classifier with 500 trees
rf_model <- randomForest::randomForest(sig_matrix, y = as.factor(labels), ntree=500)

# Plot the variable importance scores
varImpPlot(rf_model)

# Predict the cohort labels for the training data
pred_labels <- predict(rf_model, sig_matrix)

# Evaluate the performance of the classifier using confusion matrix and classification report
conf_mat <- table(labels, pred_labels)
print(conf_mat)
precision <- conf_mat[2,2] / sum(conf_mat[,2])
recall <- conf_mat[2,2] / sum(conf_mat[2,])
f1_score <- 2 * precision * recall / (precision + recall)
cat("Precision: ", precision, "\n")
cat("Recall: ", recall, "\n")
cat("F1-score: ", f1_score, "\n")

```
Create ROC
```{r}
library(ROCR)

pred_labels <- predict(rf_model, sig_matrix, type = "prob")
roc_pred <- prediction(pred_labels[, 2], labels)
roc_perf <- performance(roc_pred, "tpr", "fpr")

plot(roc_perf, main = "ROC Curve", colorize = TRUE)

```
Randomforest with cross-validation

```{r}
library(randomForest)
library(caret)

sig_matrix <- as.matrix(try[,-1])
sig_matrix = sig_matrix[-c(41:60),]
labels <- rep(c("A","B"), each=20)

# Set up the data
#data <- your_data_frame

# Set up the training control for cross-validation
train_control <- trainControl(method = "cv", # 10-fold cross-validation
                              number = 10,
                              verboseIter = TRUE,
                              returnResamp = "all")

# Train the random forest model
sig_matrix = as.data.frame.matrix(sig_matrix)
colnames(sig_matrix) <- make.names(colnames(sig_matrix))

# Create the formula
formula <- as.factor(labels) ~ .

# Create the model frame
mf <- model.frame(formula, data = sig_matrix)

# Fit the model using the model frame
model <- caret::train(formula = formula, data = mf, method = "rf", trControl = train_control)

model <- caret::train(as.factor(labels) ~ ., data = sig_matrix, 
               method = "rf", # Random Forest
               trControl = train_control)

# Print the results
print(model$results)
```


Try another randomForest package
```{r}
library(randomForestSRC)

sig_matrix <- as.matrix(try[,-1])
sig_matrix = sig_matrix[-c(21:40),]
labels <- rep(c("A","B"), each=20)

# Convert labels to a factor
labels <- as.factor(labels)

# Fit the model using k-fold cross-validation
cv_rf <- rfsrc(labels ~ ., 
               data = data.frame(sig_matrix, labels), 
               ntree = 500, 
               cv.fold = 10)

# Print the cross-validation results
cv_rf
```

Take counts and see how it performs

```{r}
try = as.data.frame(out) %>% select(from_label, to_label, p_lt, group_by)
 try$key = paste(try$from_label, try$to_label, sep = "_")
 try = try %>% select(-c(from_label, to_label))

 try = spread(try, key = key, value = p_lt)
 
 sig_matrix <- as.matrix(try[,-1])
  sig_matrix = sig_matrix[-c(41:60),]
  labels <- rep(c("A","B"), each=20)

# Convert labels to a factor
  labels <- as.factor(labels)

# Fit the model using k-fold cross-validation
  cv_rf <- rfsrc(labels ~ ., 
               data = data.frame(sig_matrix, labels), 
               ntree = 500, 
               cv.fold = 10)

# Print the cross-validation results
  cv_rf
```

heatmap with p-value
```{r}
try = as.data.frame(out) %>% select(from_label, to_label, ct, group_by)
 try$key = paste(try$from_label, try$to_label, sep = "_")
 try = try %>% select(-c(from_label, to_label))

 try = spread(try, key = key, value = ct)
 try = try[-c(41:60),]

 rownames(try) = try$group_by
 pheatmap(try[,-1], treeheight_row = 0, treeheight_col = 0)
```






